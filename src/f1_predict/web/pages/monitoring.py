"""Monitoring Dashboard - Real-time model performance, drift detection, and explainability.

Provides comprehensive visualization of model performance metrics, drift detection,
alerts, SHAP-based explainability insights, and model comparison across all deployed models.
"""

import tempfile
from typing import Any

import pandas as pd
import streamlit as st
import structlog

from f1_predict.web.utils.drift_detection import DriftDetector
from f1_predict.web.utils.monitoring_dashboard import (
    ChartBuilders,
    DataLoaders,
    TableFormatters,
    display_dashboard_info_box,
)
from f1_predict.web.utils.monitoring_explainability import ShapExplainabilityMonitor
from f1_predict.web.utils.monitoring_explainability_dashboard import (
    ExplainabilityChartBuilders,
    ExplainabilityDataLoaders,
    ExplainabilityTableFormatters,
)
from f1_predict.web.utils.monitoring_factory import (
    get_alerting_system,
    get_performance_tracker,
    is_database_backend_enabled,
)

logger = structlog.get_logger(__name__)


@st.cache_resource  # type: ignore[misc]
def get_monitoring_systems() -> dict[str, Any]:
    """Get or initialize monitoring systems.

    Uses factory pattern to select between file-based and database-backed
    implementations based on MONITORING_DB_ENABLED environment variable.

    Returns:
        Dictionary with monitoring system instances
    """
    temp_dir = tempfile.gettempdir()
    return {
        "performance_tracker": get_performance_tracker(temp_dir),
        "alerting_system": get_alerting_system(temp_dir),
        "drift_detector": DriftDetector(),
        "backend_enabled": is_database_backend_enabled(),
    }


def _display_performance_dashboard() -> None:
    """Display performance monitoring dashboard."""
    st.subheader("ğŸ“Š Performance Monitoring")

    systems = get_monitoring_systems()
    perf_tracker = systems["performance_tracker"]

    # Time range selector
    col1, col2, col3 = st.columns(3)
    with col1:
        time_range = st.selectbox(
            "Time Range",
            ["Last 24 hours", "Last 7 days", "Last 30 days"],
            key="perf_time_range",
        )
    with col2:
        st.checkbox("Auto-refresh", value=False, key="perf_auto_refresh")
    with col3:
        st.button("ğŸ”„ Refresh", key="perf_refresh")

    hours_map = {
        "Last 24 hours": 24,
        "Last 7 days": 168,
        "Last 30 days": 720,
    }
    hours = hours_map.get(time_range, 24)

    # Load performance data
    performance_data = DataLoaders.load_performance_trend(perf_tracker, hours)
    health_snapshots = DataLoaders.load_health_snapshots(perf_tracker, limit=100)

    if performance_data.empty:
        display_dashboard_info_box(
            "No Data Available",
            "Performance data will appear here once predictions are recorded.",
        )
        return

    # Performance KPIs
    st.markdown("#### Key Performance Indicators")
    if not health_snapshots.empty:
        latest_health = health_snapshots.iloc[0].to_dict()
        previous_health = (
            health_snapshots.iloc[1].to_dict() if len(health_snapshots) > 1 else latest_health
        )

        health_data = {
            "accuracy": latest_health.get("accuracy", 0.0),
            "accuracy_delta": (
                latest_health.get("accuracy", 0.0) - previous_health.get("accuracy", 0.0)
            ),
            "precision": latest_health.get("precision", 0.0),
            "precision_delta": (
                latest_health.get("precision", 0.0) - previous_health.get("precision", 0.0)
            ),
            "recall": latest_health.get("recall", 0.0),
            "recall_delta": (
                latest_health.get("recall", 0.0) - previous_health.get("recall", 0.0)
            ),
            "f1_score": latest_health.get("f1_score", 0.0),
            "f1_delta": (
                latest_health.get("f1_score", 0.0) - previous_health.get("f1_score", 0.0)
            ),
        }

        ChartBuilders.create_model_health_scorecard(health_data)
    else:
        display_dashboard_info_box("Insufficient Data", "Health snapshots not yet available")

    # Accuracy trend chart
    st.markdown("#### Accuracy Trend")
    if not performance_data.empty and "accuracy" in performance_data.columns:
        fig = ChartBuilders.create_accuracy_trend_chart(performance_data)
        st.plotly_chart(fig, use_container_width=True)
    else:
        display_dashboard_info_box("No Accuracy Data", "Accuracy data not available")

    # Confidence distribution
    st.markdown("#### Prediction Confidence Distribution")
    st.info("â„¹ï¸ Shows distribution of prediction confidence scores")
    # In production, this would load actual confidence data
    st.info("Data will appear once predictions are made")

    # Performance degradation alerts
    st.markdown("#### Performance Degradation Alerts")
    if not health_snapshots.empty:
        degraded_models = health_snapshots[
            health_snapshots.get("degradation_detected", False)
        ]
        if not degraded_models.empty:
            st.warning("âš ï¸ Performance degradation detected in some models")
            st.dataframe(TableFormatters.format_health_snapshot_table(degraded_models))
        else:
            display_dashboard_info_box(
                "All Systems Nominal", "No performance degradation detected"
            )
    else:
        st.info("â„¹ï¸ No health data to display")


def _display_drift_detection_dashboard() -> None:
    """Display drift detection dashboard."""
    st.subheader("ğŸ” Drift Detection")

    # Drift threshold
    col1, col2 = st.columns(2)
    with col1:
        psi_threshold = st.slider(
            "PSI Threshold", 0.0, 0.5, 0.25, step=0.05, key="psi_threshold"
        )
    with col2:
        ks_threshold = st.slider(
            "KS Test P-Value Threshold", 0.0, 0.1, 0.05, step=0.01, key="ks_threshold"
        )

    display_dashboard_info_box(
        "Drift Detection",
        f"Monitoring feature distributions using PSI (threshold: {psi_threshold}) and KS Test (p-value: {ks_threshold})",
    )

    # Drift status heatmap
    st.markdown("#### Feature Drift Status")
    st.info("â„¹ï¸ Green = no drift, Yellow = moderate drift, Red = significant drift")

    # PSI trends
    st.markdown("#### PSI Trends Over Time")
    st.info("â„¹ï¸ Population Stability Index tracks distribution changes")

    # Flagged features
    st.markdown("#### Flagged Features")
    st.info("â„¹ï¸ Features exceeding drift thresholds will be highlighted here")

    # Distribution comparison
    st.markdown("#### Distribution Comparison")
    col1, col2 = st.columns(2)
    with col1:
        st.selectbox(
            "Select Feature to Compare", ["Feature 1", "Feature 2", "Feature 3"],
            key="feature_select"
        )
    with col2:
        st.info("Select a feature to compare baseline vs current distribution")


def _display_alert_management() -> None:
    """Display alert management interface."""
    st.subheader("ğŸš¨ Alert Management")

    systems = get_monitoring_systems()
    alerting_system = systems["alerting_system"]

    # Alert tabs
    tab1, tab2, tab3, tab4 = st.tabs(
        ["Alert History", "Alert Rules", "Statistics", "Configuration"]
    )

    with tab1:
        st.markdown("#### Alert History")
        alerts_df = DataLoaders.load_recent_alerts(alerting_system)

        if not alerts_df.empty:
            st.markdown(f"**Recent Alerts ({len(alerts_df)} total)**")
            formatted_alerts = TableFormatters.format_alert_table(alerts_df)
            st.dataframe(formatted_alerts, use_container_width=True)

            # Alert acknowledgment
            st.markdown("#### Acknowledge Alerts")
            alert_id = st.selectbox("Select Alert to Acknowledge", alerts_df.index)
            if st.button("âœ“ Acknowledge"):
                alerting_system.acknowledge_alert(str(alert_id))
                st.success("Alert acknowledged")
        else:
            display_dashboard_info_box(
                "No Alerts", "No alerts in the recent history. System is operating normally."
            )

    with tab2:
        st.markdown("#### Alert Rules")
        st.info("â„¹ï¸ Configure rules that trigger alerts")

        col1, col2 = st.columns(2)
        with col1:
            metric_name = st.selectbox(
                "Metric",
                ["accuracy", "precision", "recall", "f1_score"],
                key="alert_metric",
            )
        with col2:
            comparison = st.selectbox(
                "Condition", ["<", ">", "<=", ">=", "=="], key="alert_condition"
            )

        threshold = st.slider("Threshold", 0.0, 1.0, 0.8, key="alert_threshold")
        st.selectbox("Severity", ["INFO", "WARNING", "CRITICAL"], key="alert_severity")

        if st.button("+ Add Rule"):
            st.success(f"Rule added: {metric_name} {comparison} {threshold}")

    with tab3:
        st.markdown("#### Alert Statistics")
        if not alerts_df.empty:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total Alerts", len(alerts_df))
            with col2:
                critical_count = len(alerts_df[alerts_df["severity"] == "CRITICAL"])
                st.metric("Critical", critical_count)
            with col3:
                warning_count = len(alerts_df[alerts_df["severity"] == "WARNING"])
                st.metric("Warnings", warning_count)

            # Alert timeline
            fig = ChartBuilders.create_alert_timeline(alerts_df)
            st.plotly_chart(fig, use_container_width=True)
        else:
            display_dashboard_info_box("No Statistics", "Alerts not yet available")

    with tab4:
        st.markdown("#### Alert Configuration")
        st.info("â„¹ï¸ Configure alert delivery channels")

        st.checkbox("Console Output", value=True)
        st.checkbox("File Logging", value=True)
        enable_email = st.checkbox("Email Notifications", value=False)
        enable_slack = st.checkbox("Slack Integration", value=False)

        if enable_email:
            st.text_area("Email Recipients (comma-separated)")

        if enable_slack:
            st.text_input("Slack Webhook URL", type="password")

        if st.button("ğŸ’¾ Save Configuration"):
            st.success("Alert configuration saved")


def _display_model_comparison() -> None:
    """Display model comparison dashboard."""
    st.subheader("ğŸ“ˆ Model Comparison")

    # Model selection
    col1, col2, col3 = st.columns(3)
    with col1:
        model1 = st.selectbox(
            "Model 1", ["Ensemble", "XGBoost", "LightGBM", "Random Forest"], key="model1"
        )
    with col2:
        model2 = st.selectbox(
            "Model 2", ["XGBoost", "Ensemble", "LightGBM", "Random Forest"], key="model2"
        )
    with col3:
        st.button("ğŸ”„ Compare")

    st.markdown("#### Performance Metrics Comparison")

    # Side-by-side metrics
    col1, col2 = st.columns(2)

    with col1:
        st.markdown(f"**{model1}**")
        m1_data = {
            "Accuracy": 0.852,
            "Precision": 0.834,
            "Recall": 0.821,
            "F1 Score": 0.827,
        }
        st.metric("Accuracy", f"{m1_data['Accuracy']:.3f}")
        st.metric("Precision", f"{m1_data['Precision']:.3f}")
        st.metric("Recall", f"{m1_data['Recall']:.3f}")
        st.metric("F1 Score", f"{m1_data['F1 Score']:.3f}")

    with col2:
        st.markdown(f"**{model2}**")
        m2_data = {
            "Accuracy": 0.831,
            "Precision": 0.812,
            "Recall": 0.798,
            "F1 Score": 0.805,
        }
        st.metric("Accuracy", f"{m2_data['Accuracy']:.3f}")
        st.metric("Precision", f"{m2_data['Precision']:.3f}")
        st.metric("Recall", f"{m2_data['Recall']:.3f}")
        st.metric("F1 Score", f"{m2_data['F1 Score']:.3f}")

    # Comparison chart
    st.markdown("#### Performance Trend Comparison")

    model_metrics = pd.DataFrame(
        {
            "model_name": [model1, model2],
            "accuracy": [0.852, 0.831],
            "precision": [0.834, 0.812],
            "recall": [0.821, 0.798],
            "f1_score": [0.827, 0.805],
        }
    )

    fig = ChartBuilders.create_model_comparison_chart(model_metrics)
    st.plotly_chart(fig, use_container_width=True)

    # Deployment status
    st.markdown("#### Deployment Status")
    col1, col2 = st.columns(2)

    with col1:
        st.write(f"**{model1}**")
        st.info("âœ“ Active | Last Updated: 2025-10-20 10:30:15")

    with col2:
        st.write(f"**{model2}**")
        st.info("â¸ Standby | Last Updated: 2025-10-15 14:22:45")


def _display_explainability_dashboard() -> None:
    """Display explainability dashboard with SHAP insights."""  # noqa: PLR0912,PLR0915,C901
    st.subheader("ğŸ” Model Explainability & Insights")

    temp_dir = tempfile.gettempdir()

    # Initialize explainability monitor
    try:
        explainability_monitor = ShapExplainabilityMonitor(data_dir=temp_dir)
    except Exception as e:
        st.error(f"Failed to initialize explainability monitor: {str(e)}")
        return

    # Tabs for different explainability views
    exp_tab1, exp_tab2, exp_tab3 = st.tabs(
        ["Feature Importance ğŸ“Š", "Drift Explanation ğŸ”", "Degradation Analysis ğŸ“‰"]
    )

    with exp_tab1:
        st.markdown("#### Feature Importance Over Time")

        # Feature selection
        features = list(explainability_monitor.feature_importance_history.keys())
        if features:
            selected_feature = st.selectbox("Select Feature", features, key="feature_select")

            # Display feature importance heatmap
            st.info("ğŸ“Š Feature importance trends across time periods")

            # Create heatmap
            importance_history = explainability_monitor.feature_importance_history
            fig_heatmap = ExplainabilityChartBuilders.create_feature_importance_heatmap(
                importance_history, limit=10
            )
            st.plotly_chart(fig_heatmap, use_container_width=True)

            # Show detailed table for selected feature
            st.markdown(f"**Detailed Trend for {selected_feature}**")
            trend_data = explainability_monitor.get_feature_importance_trend(selected_feature)
            if trend_data:
                trend_df = pd.DataFrame(trend_data)
                st.dataframe(trend_df, use_container_width=True)
            else:
                display_dashboard_info_box("No Data", f"No importance history for {selected_feature}")
        else:
            display_dashboard_info_box(
                "No Feature Data",
                "Feature importance data will appear once model predictions are tracked",
            )

    with exp_tab2:
        st.markdown("#### Drift Explanation")

        # Load recent drift explanations
        st.info("ğŸ” SHAP-based drift explanations with feature attribution")

        recent_drifts = ExplainabilityDataLoaders.load_recent_drift_explanations(
            explainability_monitor, limit=5
        )

        if recent_drifts:
            # Select drift to display
            drift_options = [f"{d.feature_name} ({d.drift_type})" for d in recent_drifts]
            selected_idx = st.selectbox(
                "Select Drift Event", range(len(recent_drifts)), format_func=lambda i: drift_options[i]
            )
            selected_drift = recent_drifts[selected_idx]

            # Display drift visualization
            col1, col2 = st.columns(2)

            with col1:
                fig_drift = ExplainabilityChartBuilders.create_drift_explanation_chart(
                    selected_drift
                )
                st.plotly_chart(fig_drift, use_container_width=True)

            with col2:
                st.markdown("**Drift Details**")
                drift_table = ExplainabilityTableFormatters.format_drift_explanation(selected_drift)
                st.dataframe(drift_table, use_container_width=True)

            # Contributing features
            st.markdown("**Contributing Features**")
            if selected_drift.contributing_features:
                for feature in selected_drift.contributing_features[:5]:
                    st.info(f"â€¢ {feature}")
            else:
                st.info("No contributing features identified")
        else:
            display_dashboard_info_box(
                "No Drift Data",
                "Drift explanations will appear once drift is detected",
            )

    with exp_tab3:
        st.markdown("#### Performance Degradation Analysis")

        # Load degradation analyses
        st.info("ğŸ“‰ Root cause analysis of performance degradation with SHAP values")

        degradation_analyses = explainability_monitor.get_degradation_analyses(limit=5)

        if degradation_analyses:
            # Select analysis to display
            analysis_options = [
                f"{a.metric_name} ({a.degradation_percent:.1f}% degradation)"
                for a in degradation_analyses
            ]
            selected_idx = st.selectbox(
                "Select Degradation Event",
                range(len(degradation_analyses)),
                format_func=lambda i: analysis_options[i],
            )
            selected_analysis = degradation_analyses[selected_idx]

            # Display degradation visualization and analysis
            col1, col2 = st.columns(2)

            with col1:
                fig_deg = ExplainabilityChartBuilders.create_degradation_analysis_chart(
                    selected_analysis
                )
                st.plotly_chart(fig_deg, use_container_width=True)

            with col2:
                st.markdown("**Degradation Details**")
                deg_table = ExplainabilityTableFormatters.format_degradation_analysis(
                    selected_analysis
                )
                st.dataframe(deg_table, use_container_width=True)

            # Top contributing features
            st.markdown("**Top Contributing Features**")
            if selected_analysis.top_contributing_features:
                top_features_chart = ExplainabilityChartBuilders.create_top_features_chart(
                    selected_analysis.top_contributing_features[:5]
                )
                st.plotly_chart(top_features_chart, use_container_width=True)

                features_table = ExplainabilityTableFormatters.format_feature_importance_table(
                    selected_analysis.top_contributing_features[:5]
                )
                st.dataframe(features_table, use_container_width=True)
            else:
                st.info("No contributing features identified")

            # Recommendations
            st.markdown("**Recommendations**")
            if selected_analysis.recommended_actions:
                for i, action in enumerate(selected_analysis.recommended_actions, 1):
                    st.info(f"{i}. {action}")
            else:
                st.info("No specific recommendations available")
        else:
            display_dashboard_info_box(
                "No Degradation Data",
                "Performance degradation analysis will appear once degradation is detected",
            )


def show_monitoring_page() -> None:
    """Main monitoring dashboard page."""
    st.set_page_config(page_title="Monitoring", page_icon="ğŸ“Š", layout="wide")

    st.title("ğŸš¨ Model Monitoring Dashboard")
    st.markdown(
        "Real-time monitoring of model performance, drift detection, and system alerts"
    )

    st.divider()

    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        [
            "Performance ğŸ“Š",
            "Drift Detection ğŸ”",
            "Alerts ğŸš¨",
            "Explainability ğŸ”¬",
            "Model Comparison ğŸ“ˆ",
        ]
    )

    with tab1:
        _display_performance_dashboard()

    with tab2:
        _display_drift_detection_dashboard()

    with tab3:
        _display_alert_management()

    with tab4:
        _display_explainability_dashboard()

    with tab5:
        _display_model_comparison()

    # Footer
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ“Š Export Report"):
            st.info("ğŸ“¥ Report export functionality coming soon")
    with col2:
        if st.button("âš™ï¸ Configure Alerts"):
            st.info("âš™ï¸ Alert configuration in Alerts tab")
    with col3:
        if st.button("ğŸ”„ Full Refresh"):
            st.rerun()
